{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37576f1d-c379-45ce-b025-ab3edb895849",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1 id='scaling-standardization-and-normalization' style='color:#7159c1'>ðŸ”¨ Scaling, Standardization and Normalization ðŸ”¨</h1>\n",
    "    <i>Transforming Numerical Variables</i>\n",
    "</center>\n",
    "\n",
    "```\n",
    "- Scaling\n",
    "- Standardization\n",
    "- Normalization\n",
    "- Conclusions\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<h1 id='0-scaling' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>0 | Scaling</h1>\n",
    "\n",
    "It's used to change the RANGE of the datas. The RANGE goes from 0 to 1.\n",
    "\n",
    "About the models, you'll need to scale the datas when you're using methods based on measures of how far apart data points are, like the models:\n",
    "\t\n",
    "```\n",
    "/ Gradient Descent Optimization\n",
    "/ Support Vector Machines (SVM)\n",
    "/ K-Nearest Neighbors (KNN) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90299a04-52ee-457d-acb9-0bf201a97d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15729627, 0.08316008, 0.05834186, ..., 0.52926281, 0.49078253,\n",
       "        0.24690435],\n",
       "       [0.05255843, 0.3014553 , 0.04298874, ..., 0.59203897, 0.36868869,\n",
       "        0.04065231],\n",
       "       [0.15552748, 0.28690229, 0.16888434, ..., 0.33322136, 0.57651802,\n",
       "        0.50091117],\n",
       "       ...,\n",
       "       [0.10511687, 0.09147609, 0.03172979, ..., 0.5112917 , 0.4492287 ,\n",
       "        0.15625438],\n",
       "       [0.09854706, 0.23284823, 0.12998976, ..., 0.45870908, 0.61933562,\n",
       "        0.24335311],\n",
       "       [0.36955148, 0.06860707, 0.21084954, ..., 0.43312834, 0.47079296,\n",
       "        0.1416289 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Reading Dataset ----\n",
    "import pandas as pd # pip install pd\n",
    "from sklearn.model_selection import train_test_split # pip install sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ---- Scaling ----\n",
    "houses_df = pd.read_csv('./datasets/melb_data.csv')\n",
    "houses_df = houses_df.select_dtypes(exclude=['object'])\n",
    "x_train_df, x_valid_df, y_train_df, y_valid_df = train_test_split(\n",
    "    houses_df.loc[:, 'Price':]\n",
    "    , houses_df.loc[:, 'Rooms']\n",
    "    , train_size=0.70\n",
    "    , test_size=0.30\n",
    ")\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "scaled_x_train_df = min_max_scaler.fit_transform(x_train_df)\n",
    "scaled_x_valid_df = min_max_scaler.transform(x_valid_df)\n",
    "\n",
    "scaled_x_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6c7b4-856c-4289-85db-551a2df8c640",
   "metadata": {},
   "source": [
    "<h1 id='1-standardization' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>1 | Standardization</h1>\n",
    "\n",
    "It's like the Scale, but the scale range doesn't go from 0 to 1, it varies.\n",
    "\n",
    "About the models, you'll need to scale the datas when you're using methods based on measures of how far apart data points are, like the models:\n",
    "\n",
    "```\n",
    "/ Gradient Descent Optimization\n",
    "/ Support Vector Machines (SVM)\n",
    "/ K-Nearest Neighbors (KNN)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3233d028-5b3d-4a27-a719-c38d1a73c9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.619585  , -0.79411765, -0.25961538, ...,  0.29404171,\n",
       "        -0.19422401, -0.16730164],\n",
       "       [-0.58755005,  0.75      , -0.40384615, ...,  0.77656405,\n",
       "        -1.12983494, -0.8984595 ],\n",
       "       [ 0.59919913,  0.64705882,  0.77884615, ..., -1.21281033,\n",
       "         0.46277117,  0.7331456 ],\n",
       "       ...,\n",
       "       [ 0.01820167, -0.73529412, -0.50961538, ...,  0.15590864,\n",
       "        -0.512653  , -0.4886533 ],\n",
       "       [-0.05751729,  0.26470588,  0.41346154, ..., -0.24826216,\n",
       "         0.79088446, -0.17989067],\n",
       "       [ 3.06589006, -0.89705882,  1.17307692, ..., -0.4448858 ,\n",
       "        -0.34740503, -0.54050025]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Robust Scaler ----\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "robust_scaler = RobustScaler()\n",
    "robust_scaled_x_train_df = robust_scaler.fit_transform(x_train_df)\n",
    "robust_scaled_x_valid_df = robust_scaler.transform(x_valid_df)\n",
    "\n",
    "robust_scaled_x_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2119ec13-96cf-4f76-980c-16bcc06c0c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3873995 , -1.05932158, -0.53401387, ...,  0.46163746,\n",
       "        -0.19196051, -0.43866295],\n",
       "       [-0.90198338,  0.74442916, -0.69943005, ...,  1.07550397,\n",
       "        -1.35938169, -1.44046555],\n",
       "       [ 0.36562463,  0.62417911,  0.65698262, ..., -1.45538466,\n",
       "         0.62781409,  0.79509304],\n",
       "       ...,\n",
       "       [-0.25495892, -0.99060726, -0.82073524, ...,  0.28590411,\n",
       "        -0.58928459, -0.87896586],\n",
       "       [-0.33583698,  0.17753607,  0.2379283 , ..., -0.22828332,\n",
       "         1.03722188, -0.45591193],\n",
       "       [ 3.0003829 , -1.17957163,  1.10912018, ..., -0.47842855,\n",
       "        -0.3830942 , -0.95000442]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Standard Scaler ----\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaled_x_train_df = standard_scaler.fit_transform(x_train_df)\n",
    "standard_scaled_x_valid_df = standard_scaler.transform(x_valid_df)\n",
    "\n",
    "standard_scaled_x_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96117179-9a0b-4642-84c3-6ee04635ec64",
   "metadata": {},
   "source": [
    "<h1 id='2-normalization' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>2 | Normalization</h1>\n",
    "\n",
    "It's used to change the DISTRIBUTION of the data. In a nutshell, Normalization just changes the distribution of the datas in order to get a Normal Distribution (Gaussian Distribution or Bell Curve).\n",
    "\n",
    "About the models, you'll need to normalize the datas when using:\n",
    "\n",
    "```\n",
    "/ Linear Discriminant Analysis (LDA)\n",
    "/ Gaussian Naive Bayes\n",
    "```\n",
    "\n",
    "Tip: any method with \"Gaussian\" in the name probably needs that you normalize the datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70103d49-d77e-4444-b828-8f2fe7210621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.99987672e-01,  3.00748172e-06,  2.29846790e-03, ...,\n",
       "        -2.84003190e-05,  1.09002438e-04,  4.16009909e-03],\n",
       "       [ 9.99970967e-01,  2.89412755e-05,  6.07168001e-03, ...,\n",
       "        -7.52958179e-05,  2.89119949e-04,  2.23346809e-03],\n",
       "       [ 9.99990810e-01,  7.88855859e-06,  3.49880775e-03, ...,\n",
       "        -4.39141208e-05,  1.68075184e-04,  9.30385881e-04],\n",
       "       ...,\n",
       "       [ 9.99984701e-01,  4.79818177e-06,  3.30529294e-03, ...,\n",
       "        -4.12063489e-05,  1.58049490e-04,  3.91815161e-03],\n",
       "       [ 9.99970921e-01,  1.29476004e-05,  3.61492378e-03, ...,\n",
       "        -4.37299422e-05,  1.67744486e-04,  6.30848707e-03],\n",
       "       [ 9.99998638e-01,  1.09634402e-06,  1.06511483e-03, ...,\n",
       "        -1.25738367e-05,  4.81577750e-05,  1.08969951e-03]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Normalization ----\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "x_train_df.dropna(inplace=True)\n",
    "x_valid_df.dropna(inplace=True)\n",
    "\n",
    "normalizer = Normalizer()\n",
    "normalized_x_train_df = normalizer.fit_transform(x_train_df)\n",
    "normalized_x_valid_df = normalizer.transform(x_valid_df)\n",
    "\n",
    "normalized_x_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34785e19-9ac6-4e0c-8fd3-8494f3fc17e4",
   "metadata": {},
   "source": [
    "<h1 id='3-conclusions' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>3 | Conclusions</h1>\n",
    "\n",
    "> **Explanation Scale/Standardization**\n",
    "\n",
    "It's like to scale Real to Dollar, where 1 dollar is equals 5 reals nowadays. So, if we don't use the Scale, the model will consider 1 dollar equals to 1 real, and that's not true.\n",
    "\n",
    "Another example is the height and weight, where we gotta scale the datas, like where 1 inch is equals 2.54 cm, and 1 pound is equals 0.45 kg.\n",
    "\n",
    "---\n",
    "\n",
    "> **Another Explanation Just to Get the Feeling**\n",
    "\n",
    "Scale, Standardization and Normalization avoid the model considers some features more important than others by the scale, like consider the salary (from 40,000 to 210,000) more important than the age (from 18 to 100)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f446b379-ddb9-4289-aeb1-f420a6e63c7f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1 id='reach-me' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>ðŸ“« | Reach Me</h1>\n",
    "\n",
    "> **Email** - [csfelix08@gmail.com](mailto:csfelix08@gmail.com?)\n",
    "\n",
    "> **Linkedin** - [linkedin.com/in/csfelix/](https://www.linkedin.com/in/csfelix/)\n",
    "\n",
    "> **GitHub:** - [CSFelix](https://github.com/CSFelix)\n",
    "\n",
    "> **Kaggle** - [DSFelix](https://www.kaggle.com/dsfelix)\n",
    "\n",
    "> **Portfolio** - [CSFelix.io](https://csfelix.github.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

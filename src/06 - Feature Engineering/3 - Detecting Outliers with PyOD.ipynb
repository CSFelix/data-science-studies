{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e0633f0-5cc9-4ec0-ac8f-9bc2fddeb426",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1 id='detecting-outliers-with-pyod' style='color:#7159c1'>⚙️ Detecting Outliers with PyOD ⚙️</h1>\n",
    "    <i>Outliers Identification</i>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "`PyOD` is a Python package to identify outliers in datasets. In a nutshell, it contains the following models:\n",
    "\n",
    "> **Angle-Based Outlier Detection (ABOD)** - `It considers the relationship between each point and its neighbor(s). It does not consider the relationships among these neighbors. The variance of its weighted cosine scores to all neighbors could be viewed as the outlying score`;\n",
    "\n",
    ">> `ABOD performs well on multi-dimensional data`;\n",
    "\n",
    ">>> `PyOD provides two different versions of ABOD: Fast ABOD: 1) Uses k-nearest neighbors to approximate; 2) Original ABOD: Considers all training points with high-time complexity`.\n",
    "\n",
    "<br />\n",
    "\n",
    "> **k-Nearest Neighbors Detector** - `For any data point, the distance to its kth nearest neighbor could be viewed as the outlying score`;\n",
    "\n",
    ">> `PyOD supports three kNN detectors: 1) Largest: Uses the distance of the kth neighbor as the outlier score; 2) Mean: Uses the average of all k neighbors as the outlier score; 3) Median: Uses the median of the distance to k neighbors as the outlier score`.\n",
    "\n",
    "<br />\n",
    "\n",
    "> **Isolation Forest** - `It uses the scikit-learn library internally. In this method, data partitioning is done using a set of trees. Isolation Forest provides an anomaly score looking at how isolated the point is in the structure. The anomaly score is then used to identify outliers from normal observations`;\n",
    "\n",
    ">> `Isolation Forest performs well on multi-dimensional data`.\n",
    "\n",
    "<br />\n",
    "\n",
    "> **Histogram-based Outlier Detection** -`It is an efficient unsupervised method which assumes the feature independence and calculates the outlier score by building histograms`;\n",
    "\n",
    ">> `It is much faster than multivariate approaches, but at the cost of less precision`.\n",
    "\n",
    "<br />\n",
    "\n",
    "> **Feature Bagging** - `A feature bagging detector fits a number of base detectors on various sub-samples of the dataset. It uses averaging or other combination methods to improve the prediction accuracy`;\n",
    "\n",
    ">> `By default, Local Outlier Factor (LOF) is used as the base estimator. However, any estimator could be used as the base estimator, such as kNN and ABOD`;\n",
    "\n",
    ">>> `Feature bagging first constructs n sub-samples by randomly selecting a subset of features. This brings out the diversity of base estimators. Finally, the prediction score is generated by averaging or taking the maximum of all base detectors`.\n",
    "\n",
    "<br />\n",
    "\n",
    "> **Clustering Based Local Outlier Factor** - `It classifies the data into small clusters and large clusters. The anomaly score is then calculated based on the size of the cluster the point belongs to, as well as the distance to the nearest large cluster`.\n",
    "\n",
    "<br />\n",
    "\n",
    "> **Extra Utilities provided by PyOD** - `A function \"generate_data\" can be used to generate random data with outliers. Inliers data is generated by a multivariate Gaussian distribution and outliers are generated by a uniform distribution`;\n",
    "\n",
    ">> `We can provide our own values of outliers fraction and the total number of samples that we want in our dataset. We will use this utility function to create data in the implementation part`.\n",
    "\n",
    "---\n",
    "\n",
    "In particular, we can use PyOD with in two approaches:\n",
    "\n",
    "```\n",
    "- Single Model\n",
    "- Combining Multiple Models\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f4db2-3f5a-4900-9aee-39afa3fbcd0b",
   "metadata": {},
   "source": [
    "<h1 id='0-single-model' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>0 | Single Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5869b743-3bec-4604-a6c7-58f302e5b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Settings ----\n",
    "#\n",
    "# pip install pyod\n",
    "# pip install combo\n",
    "#\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.utils.data import evaluate_print\n",
    "\n",
    "# ---- Defining Fraction for Outliers ----\n",
    "from random import randrange # pip install random\n",
    "out_frac = randrange(0, 45) / 100\n",
    "\n",
    "# ---- Reading Dataset and Splitting into Training and Validation ----\n",
    "import pandas as pd # pip install pandas\n",
    "import numpy as np # pip install numpy\n",
    "from sklearn.model_selection import train_test_split # pip install sklearn\n",
    "\n",
    "autos_df = pd.read_csv('./datasets/autos.csv')\n",
    "autos_df = autos_df.select_dtypes(exclude=['object'])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    autos_df.loc[:, 'symboling':'highway_mpg']\n",
    "    , autos_df.loc[:, 'price']\n",
    "    , train_size=0.70\n",
    "    , test_size=0.30\n",
    ")\n",
    "\n",
    "X_train.reset_index(inplace=True)\n",
    "X_valid.reset_index(inplace=True)\n",
    "y_train = y_train.reset_index()\n",
    "y_valid = y_valid.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcb66800-9a03-4e8e-b777-d798e80353c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNN(algorithm='auto', contamination=0.37, leaf_size=30, method='largest',\n",
       "  metric='minkowski', metric_params=None, n_jobs=4, n_neighbors=5, p=2,\n",
       "  radius=1.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Defining Methods/Models ----\n",
    "rs = np.random.RandomState(20241901)\n",
    "\n",
    "clf = { \n",
    "    'Angle-based Outlier Detector (ABOD)': ABOD(contamination=out_frac),\n",
    "    'Cluster-based Local Outlier Factor (CBLOF)': CBLOF(contamination=out_frac,check_estimator=False, random_state=rs),\n",
    "    'Isolation Forest': IForest(contamination=out_frac,random_state=rs),\n",
    "    'K Nearest Neighbors (KNN)': KNN(contamination=out_frac, method='largest', n_neighbors=5, n_jobs=4),\n",
    "    'Average KNN': KNN(method='mean', contamination=out_frac),\n",
    "    'Local Outlier Factor (LOF)':LOF(n_neighbors=35, contamination=out_frac),\n",
    "    'One-class SVM (OCSVM)': OCSVM(contamination=out_frac),\n",
    "    'Principal Component Analysis (PCA)': PCA(contamination=out_frac, random_state=rs),\n",
    "}\n",
    "\n",
    "# ---- Training K-Nearest Neighbors Model ----\n",
    "clf_name = 'K Nearest Neighbors (KNN)'\n",
    "clf[clf_name].fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a798abfa-8371-467a-bf95-3236ce5297bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Predictions and Scores ----\n",
    "\n",
    "# - Getting the prediction label and outlier socres of the training data\n",
    "y_train_pred = clf[clf_name].labels_ # bynary labels(0: inliers, 1: outliers)\n",
    "y_train_scores = clf[clf_name].decision_scores_ # raw outlier scores (distances)\n",
    "y_train_number_outliers = np.unique(y_train_pred, return_counts=True) # number of outliers\n",
    "\n",
    "y_valid_pred = clf[clf_name].predict(X_valid) # outlier labels (0 or 1)\n",
    "y_valid_scores = clf[clf_name].decision_function(X_valid) # outlier scores\n",
    "y_valid_number_outliers = np.unique(y_valid_pred, return_counts=True) # number of outliers\n",
    "\n",
    "# - Prediction Confidence\n",
    "# - Outlier Labels (0 or 1) and Confidence in the Range of [0.0, 1.0]\n",
    "y_valid_pred, y_valid_pred_confidence = clf[clf_name].predict(X_valid, return_confidence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e60edf0-25ea-41d5-9e95-be55beb27199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>7895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>120</td>\n",
       "      <td>11850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>7295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>57</td>\n",
       "      <td>18344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>105</td>\n",
       "      <td>17075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  price\n",
       "4      35   7895\n",
       "6     120  11850\n",
       "8      34   7295\n",
       "14     57  18344\n",
       "15    105  17075"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Getting Outliers ----\n",
    "outliers_indexes = [\n",
    "    index for index in range(0, len(y_train_pred))\n",
    "    if y_train_pred[index] == 1\n",
    "]\n",
    "\n",
    "outlier_rows = y_train.loc[outliers_indexes]\n",
    "outlier_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebfb165-4a70-4a67-9b9c-a07e2a4bfbb7",
   "metadata": {},
   "source": [
    "<h1 id='1-combining-multiple-models' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>1 | Combining Multiple Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2eb70212-5fb8-4345-8d0f-e53caa9067d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Settings ----\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.combination import aom, moa, average, maximization\n",
    "from pyod.utils.utility import standardizer\n",
    "\n",
    "# ---- Models ----\n",
    "k_list = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "n_clf = len(k_list) # Number of classifiers being trained\n",
    "\n",
    "# ---- Calculating Scores ----\n",
    "train_scores = np.zeros([X_train.shape[0], n_clf])\n",
    "valid_scores = np.zeros([X_valid.shape[0], n_clf])\n",
    "\n",
    "for index in range(n_clf):\n",
    "    k = k_list[index]\n",
    "    clf = KNN(n_neighbors=k, method='largest')\n",
    "    clf.fit(X_train)\n",
    "    \n",
    "    train_scores[:, index] = clf.decision_scores_\n",
    "    valid_scores[:, index] = clf.decision_function(X_valid)\n",
    "    \n",
    "# ---- Standardizating Scores before Combination ----\n",
    "train_scores_norm, valid_scores_norm = standardizer(train_scores, valid_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f930d33-9cb5-4a70-ac22-5ba3877504b8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Types of Combination:\n",
    "\n",
    "> **Average** - `average scores of all detectors`;\n",
    "\n",
    "> **Maximization** - `maximum score across all detectors`;\n",
    "\n",
    "> **Average of Maximum (AOM)** - `divide base detectors into subgroups and take the maximum score for each subgroup. The final score is the average of all subgroup scores`;\n",
    "\n",
    "> **Maximum of Average (MOA)** - `divide base detectors into subgroups and take the average score for each subgroup. The final score is the maximum of all subgroup scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8874004-fa26-4f70-b63d-0e858b3613b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.75755171,  0.44058761, -0.02151253,  1.0988025 ,  0.85565728,\n",
       "       -0.51147912, -0.61755266, -0.5316046 ,  1.8179753 , -0.12353809,\n",
       "       -0.25160918, -0.71355965, -0.69535552,  0.82597223, -0.8461039 ,\n",
       "       -0.07791699, -0.47237863, -0.99544482,  0.81987963,  3.25990955,\n",
       "       -0.84951258, -0.23601159,  0.82567168, -0.90915232,  0.28004228,\n",
       "        0.43757886, -0.8023385 ,  1.75055444, -0.82385452, -0.76821742,\n",
       "       -0.91879264, -0.65483715, -0.273635  , -0.34674645, -0.3022741 ,\n",
       "        0.98822911, -0.81200354, -0.18906244, -0.79227208, -0.79244855,\n",
       "        0.01632175, -0.36433127, -0.64715941, -1.01245975, -0.68943522,\n",
       "       -0.74030481, -0.34715944, -0.38982401, -0.73156442, -0.36422027,\n",
       "       -0.66006785, -0.58021869, -0.63825257,  3.0170915 , -0.02651536,\n",
       "       -0.5966944 , -0.65948665, -0.62706118])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Combinations ----\n",
    "comb_by_average = average(valid_scores_norm)\n",
    "comb_by_maximization = maximization(valid_scores_norm)\n",
    "comb_by_aom = aom(valid_scores_norm, 5) # 5 groups\n",
    "comb_by_moa = moa(valid_scores_norm, 5) # 5 groups\n",
    "\n",
    "comb_by_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b100c-2c82-4738-bf0b-5527ee35c4f9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1 id='reach-me' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>📫 | Reach Me</h1>\n",
    "\n",
    "> **Email** - [csfelix08@gmail.com](mailto:csfelix08@gmail.com?)\n",
    "\n",
    "> **Linkedin** - [linkedin.com/in/csfelix/](https://www.linkedin.com/in/csfelix/)\n",
    "\n",
    "> **GitHub:** - [CSFelix](https://github.com/CSFelix)\n",
    "\n",
    "> **Kaggle** - [DSFelix](https://www.kaggle.com/dsfelix)\n",
    "\n",
    "> **Portfolio** - [CSFelix.io](https://csfelix.github.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dffb5a2-2eb1-4b21-b3e7-b982cecd999f",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1 id='lstm-and-gru' style='color:#7159c1'>ðŸ§  LSTM and GRU ðŸ§ </h1>\n",
    "    <i>Two Deep Learning Algorithms for predictions with Time Series</i>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bcae94-ad0d-4154-8bcf-7a919b63b4a8",
   "metadata": {},
   "source": [
    "<h1 id='0-lstm' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>0 | LSTM</h1>\n",
    "\n",
    "> `Usefull for large datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d35c2f5-5751-47cd-8687-9dff57df0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Importations ----\n",
    "import pandas as pd # pip install pandas\n",
    "from sklearn.model_selection import train_test_split # pip install sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential # pip install keras\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "from keras.optimizers import SGD\n",
    "import math # pip install math\n",
    "\n",
    "# ---- Functions ----\n",
    "def return_rmse(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    print(\"The root mean squared error is {}.\".format(rmse))\n",
    "\n",
    "# ---- Preparing Dataset ----\n",
    "autos_df = pd.read_csv('./datasets/autos.csv')\n",
    "autos_df = autos_df.select_dtypes(exclude='object')\n",
    "\n",
    "X = autos_df.copy()\n",
    "y = X.pop('price')\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y\n",
    "    , train_size=0.70\n",
    "    , test_size=0.30\n",
    "    , random_state=20242301\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70025918-b44a-4b9c-83dd-f271ef8cd5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 7s 55ms/step - loss: 223316704.0000\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 223211568.0000\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 223153472.0000\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 223118960.0000\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 223104320.0000\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 223090864.0000\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 223074480.0000\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 223066944.0000\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 223057776.0000\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 223050112.0000\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 223040624.0000\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 223036640.0000\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 223030752.0000\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 223020448.0000\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 223013888.0000\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 223007760.0000\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 222997200.0000\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 222994000.0000\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 222989600.0000\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 222984880.0000\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 222974624.0000\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222969600.0000\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 222961520.0000\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 222961552.0000\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222946016.0000\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222945472.0000\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222935296.0000\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222930272.0000\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 222921248.0000\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222911616.0000\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222911456.0000\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 222903552.0000\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222898288.0000\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222890512.0000\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222879856.0000\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222877792.0000\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222878128.0000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 222864336.0000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222860384.0000\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222853072.0000\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 222848064.0000\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 222838832.0000\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 222832896.0000\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222825376.0000\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222821520.0000\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 222813232.0000\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222806512.0000\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 222802400.0000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 222791600.0000\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 222787856.0000\n",
      "2/2 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# ---- LSTM ----\n",
    "\n",
    "# 0.1 - The LSTM architecture\n",
    "regressor = Sequential()\n",
    "\n",
    "# First LSTM layer with Dropout regularisation\n",
    "regressor.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Second LSTM layer\n",
    "regressor.add(LSTM(units=50, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Third LSTM layer\n",
    "regressor.add(LSTM(units=50, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Fourth LSTM layer\n",
    "regressor.add(LSTM(units=50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# The output layer\n",
    "regressor.add(Dense(units=1))\n",
    "\n",
    "# 0.2 - Compiling the RNN\n",
    "regressor.compile(optimizer='rmsprop',loss='mean_squared_error')\n",
    "\n",
    "# 0.3 - Fitting to the training set\n",
    "regressor.fit(X_train, y_train,epochs=50,batch_size=32)\n",
    "\n",
    "# 0.4 - Predictions\n",
    "predicted_stock_price = regressor.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef4429d-57b1-4560-b519-f4e9763d689a",
   "metadata": {},
   "source": [
    "<h1 id='1-gru' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>1 | GRU</h1>\n",
    "\n",
    "> `Usefull for small/medium datasets and is easier to train than LSTM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b9e086c-6893-4f8c-98f2-90b5e0158e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 223327120.0000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 198070272.0000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 455722336.0000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 138221552.0000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 114965472.0000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 308655200.0000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 193307648.0000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 86063344.0000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 189185008.0000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 152796848.0000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 66818208.0000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 128554688.0000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 177236032.0000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 96336976.0000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 88229016.0000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 145790128.0000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 111687544.0000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 78452112.0000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 120791616.0000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 133196720.0000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 67279576.0000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 91665240.0000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 106609256.0000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 73287056.0000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 64406044.0000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 91954104.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 85683576.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 70490416.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 85580560.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 81143640.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 74582128.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 70346008.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 79354824.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 72217808.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 71274464.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 66237036.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 70270440.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 63677844.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 63889596.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 66825276.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 65131588.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 62771656.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 61803568.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 65510408.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 62929572.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 61511140.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 64241428.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 62485504.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 61948348.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 64079932.0000\n",
      "2/2 [==============================] - 1s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# ---- GRU ----\n",
    "\n",
    "# 1.1 - The GRU architecture\n",
    "regressorGRU = Sequential()\n",
    "\n",
    "# First GRU layer with Dropout regularisation\n",
    "regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\n",
    "regressorGRU.add(Dropout(0.2))\n",
    "\n",
    "# Second GRU layer\n",
    "regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\n",
    "regressorGRU.add(Dropout(0.2))\n",
    "\n",
    "# Third GRU layer\n",
    "regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\n",
    "regressorGRU.add(Dropout(0.2))\n",
    "\n",
    "# Fourth GRU layer\n",
    "regressorGRU.add(GRU(units=50, activation='tanh'))\n",
    "regressorGRU.add(Dropout(0.2))\n",
    "\n",
    "# The output layer\n",
    "regressorGRU.add(Dense(units=1))\n",
    "\n",
    "# 1.2 - Compiling the RNN\n",
    "regressorGRU.compile(optimizer=SGD(learning_rate=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')\n",
    "\n",
    "# 1.3 - Fitting to the training set\n",
    "regressorGRU.fit(X_train,y_train,epochs=50,batch_size=150)\n",
    "\n",
    "# 1.4 - Predictions\n",
    "GRU_predicted_stock_price = regressorGRU.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f182710-32f4-4ac3-a842-82589a9a74c6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1 id='reach-me' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>ðŸ“« | Reach Me</h1>\n",
    "\n",
    "> **Email** - [csfelix08@gmail.com](mailto:csfelix08@gmail.com?)\n",
    "\n",
    "> **Linkedin** - [linkedin.com/in/csfelix/](https://www.linkedin.com/in/csfelix/)\n",
    "\n",
    "> **GitHub:** - [CSFelix](https://github.com/CSFelix)\n",
    "\n",
    "> **Kaggle** - [DSFelix](https://www.kaggle.com/dsfelix)\n",
    "\n",
    "> **Portfolio** - [CSFelix.io](https://csfelix.github.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

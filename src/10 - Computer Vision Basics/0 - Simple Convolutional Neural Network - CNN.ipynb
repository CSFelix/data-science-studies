{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d16a15c4-88a6-4d03-a2e2-fc37dbd2287b",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1 id='simple-convolutional-neural-network' style='color:#7159c1'>üëÅÔ∏è‚Äçüó®Ô∏è Simple Convolutional Neural Network - CNN üëÅÔ∏è‚Äçüó®Ô∏è</h1>\n",
    "    <i>Diving into Computational Vision World</i>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "CNN's consist in two parts: `Convolutional Base` and `Dense Head`. Being:\n",
    "\n",
    "> **Convolutional Base** - `in these layers, the image's features (lines, patterns, color, textures, shapes and so on) are extract to be analysed. This part is often made by Convolutional Layers, but can includes other types too`;\n",
    "\n",
    "> **Dense Head** - `in these layers, the image will be classified. This part is often maded by Dense Layers, but can includes other types too, such as Dropout and BatchNormalization`.\n",
    "\n",
    "<br />\n",
    "\n",
    "One important thing to know is that most CNN's are not created by scratch, but yes, by Transfer Learning. Which means, we use a pretrained Base and add an untrained Head. Besides the model's training has two goals:\n",
    "\n",
    "1. to learn which features to extract;\n",
    "2. to learn which class these features are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "806943af-ca69-42ee-b8af-9c581d517c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Importings ----\n",
    "import os, warnings # pip install os warnings\n",
    "import matplotlib.pyplot as plt # pip install matplotlib\n",
    "from matplotlib import gridspec\n",
    "import mplcyberpunk # pip install mplcyberp√∫nk\n",
    "import numpy as np # pip install numpy\n",
    "import tensorflow as tf # pip install tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import tensorflow_hub as hub # pip install tensorflow_hub\n",
    "import pandas as pd # pip install pandas\n",
    "\n",
    "# ---- Functions ----\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# ---- Setting Matplotlib Defaults ----\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc(\n",
    "    'axes'\n",
    "    , labelweight='bold'\n",
    "    , labelsize='large'\n",
    "    , titleweight='bold'\n",
    "    , titlesize=18\n",
    "    , titlepad=10\n",
    ")\n",
    "plt.rc('image', cmap='magma')\n",
    "plt.style.use('cyberpunk')\n",
    "warnings.filterwarnings(\"ignore\") # to clean up output cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95994f8-6f92-46cd-8b28-40d6615dbc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5117 files belonging to 2 classes.\n",
      "Found 5051 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# ---- Loading Training and Validation Datasets ----\n",
    "train_df = image_dataset_from_directory(\n",
    "    './datasets/car-or-truck/train'\n",
    "    , labels='inferred' # the images folders name are the labels\n",
    "    , label_mode='binary' # either car or truck\n",
    "    , image_size=[128, 128]\n",
    "    , interpolation='nearest'\n",
    "    , batch_size=64\n",
    "    , shuffle=False\n",
    ")\n",
    "\n",
    "valid_df = image_dataset_from_directory(\n",
    "    './datasets/car-or-truck/valid'\n",
    "    , labels='inferred'\n",
    "    , label_mode='binary'\n",
    "    , image_size=[128, 128]\n",
    "    , interpolation='nearest'\n",
    "    , batch_size=64\n",
    "    , shuffle=False\n",
    ")\n",
    "\n",
    "# ---- Pipelines ----\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# ---- Transforming Datasets ----\n",
    "train_df = (\n",
    "    train_df\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n",
    "valid_df = (\n",
    "    valid_df\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1af69c8-a67c-477e-9ef7-c98e0814b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Loading Pretrained Base ----\n",
    "pretrained_base = tf.keras.models.load_model('./models/vgg16-pretrained-base')\n",
    "\n",
    "# As long the base has already been pretrained, we define it as non-trainable\n",
    "pretrained_base.trainable = False\n",
    "\n",
    "# ---- Creating the Model Head ----\n",
    "model_1 = keras.Sequential([\n",
    "    # base layer\n",
    "    pretrained_base # base to find and extract image features\n",
    "    \n",
    "    # head layer\n",
    "    , layers.Flatten() # this layer converts two dimensional input to one dimensional\n",
    "    , layers.Dense(units=6, activation='relu') # layer to find the image patterns\n",
    "    , layers.Dense(units=1, activation='sigmoid') # layer to classify the image between car and truck\n",
    "])\n",
    "\n",
    "model_2 = keras.Sequential([\n",
    "    # base layer\n",
    "    pretrained_base\n",
    "    \n",
    "    # head layer\n",
    "    , layers.GlobalAvgPool2D() # this layer supersedes/replaces all the Hidden ones (Dense and Flatten Layers)\n",
    "    , layers.Dense(units=1, activation='sigmoid')\n",
    "]) # we are going to use this head\n",
    "\n",
    "model_3 = keras.Sequential([\n",
    "    # base layer\n",
    "    layers.Conv2D(\n",
    "        filters=64\n",
    "        , kernel_size=3\n",
    "        , strides=1\n",
    "        , padding='same'\n",
    "        , activation='relu'\n",
    "    ) # this layer and the MaxPool2D replaces the pretrained_base\n",
    "    , layers.MaxPool2D(\n",
    "        pool_size=2\n",
    "        , strides=1\n",
    "        , padding='same'\n",
    "    ) # this layer and the Conv2D replaces the pretrained_base\n",
    "    \n",
    "    # head layer\n",
    "    , layers.Flatten()\n",
    "    , layers.Dense(units=6, activation='relu')\n",
    "    , layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# ---- Optimizers and Loss Functions ----\n",
    "#\n",
    "# The Optimizer, we can always use the Adam in the first moment\n",
    "#\n",
    "# About the Loss Function and the Metrics, we have to always choose\n",
    "# those ones that are appropriate for the problem.\n",
    "# How the CNN are working with binary classification, we use the\n",
    "# 'binary_crossentropy (get distribution probabilities)' and the \n",
    "# 'binary_accuracy'\n",
    "#\n",
    "optimizer = tf.keras.optimizers.Adam(epsilon=0.01)\n",
    "model_2.compile(\n",
    "    optimizer=optimizer\n",
    "    , loss='binary_crossentropy'\n",
    "    , metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "# ---- Training the Model ----\n",
    "history = model_2.fit(\n",
    "    train_df\n",
    "    , validation_data=valid_df\n",
    "    , epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec296eb-5595-471c-8591-b6af822f8757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Evaluating the Model - Loss ----\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9bc06-16db-4206-b365-49ab60ccfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Evaluating the Model - Binary Accuracy ----\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c94734b-095d-4c03-84e6-fa02f2406616",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1 id='reach-me' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>üì´ | Reach Me</h1>\n",
    "\n",
    "> **Email** - [csfelix08@gmail.com](mailto:csfelix08@gmail.com?)\n",
    "\n",
    "> **Linkedin** - [linkedin.com/in/csfelix/](https://www.linkedin.com/in/csfelix/)\n",
    "\n",
    "> **GitHub:** - [CSFelix](https://github.com/CSFelix)\n",
    "\n",
    "> **Kaggle** - [DSFelix](https://www.kaggle.com/dsfelix)\n",
    "\n",
    "> **Portfolio** - [CSFelix.io](https://csfelix.github.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

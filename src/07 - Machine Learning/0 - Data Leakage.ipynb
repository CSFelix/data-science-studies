{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d79388-faff-4ed6-b29e-e1fc94033862",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1 id='data-leakage' style='color:#7159c1'>ðŸ¤– Data Leakage ðŸ¤–</h1>\n",
    "    <i>Avoiding Leakages on Predictions and Classifications</i>\n",
    "</center>\n",
    "\n",
    "```\n",
    "- Target Leakage\n",
    "- Train-Test Contamination\n",
    "- Examples\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c9b84f-32a5-4d10-900e-db61fc7dfa45",
   "metadata": {},
   "source": [
    "<h1 id='0-target-leakage' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>0 | Target Leakage</h1>\n",
    "\n",
    "Some features (X) have their value defined AFTER the target variable (y) is defined, for example:\n",
    "\n",
    "> **y** - `got pneumonia >> True, False`;\n",
    "\n",
    "> **X** - `took antibiotic medicine >> True False`.\n",
    "\n",
    "<br />\n",
    "\n",
    "People take antibiotic medicines after getting pneumonia in order to recover. So the raw data shows a strong relationship between those columns. But \"took_antibiotic_medicine\" is frequently changed after the value for \"got_pneumonia\" is determined. This is target leakage.\n",
    "\n",
    "To prevent this type of data leakage, any variable updated (or created) after the target value is realized should be EXCLUDED. Because when we use this model to make new predictions, that data won't be available to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bea382-4be1-46bb-a27e-cefc06cd4844",
   "metadata": {},
   "source": [
    "<h1 id='1-train-test-contamination' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>1 | Train-Test Contamination</h1>\n",
    "\n",
    "`Train-Test Contamination` is a much different type of leak that occurs when you aren't careful distinguishing training data from validation data. \n",
    "\n",
    "For example, this happens if you run preprocessing (like fitting the Imputer for missing values) before calling \"train_test_split\". Validation is meant to be a measure of how the model does on data it hasn't considered before. You can corrupt this process in subtle ways if the validation data affects the preprocessing behaviour. The end result? Your model will get very good validation scores, giving you great confidence in it, but perform poorly when you deploy it to make decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6399ccc-ba16-4d0a-aef7-877066d4e75a",
   "metadata": {},
   "source": [
    "<h1 id='2-examples' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>2 | Examples</h1>\n",
    "\n",
    "Problem when you use the AVG Sales of the houses in a neighborhood to predict the price of a house in this same neighborhood: This poses a risk of both target leakage and train-test contamination (though you may be able to avoid both if you are careful).\n",
    "\n",
    "---\n",
    "\n",
    "You have target leakage if a given patient's outcome contributes to the infection rate for his surgeon, which is then plugged back into the prediction model for whether that patient becomes infected. You can avoid target leakage if you calculate the surgeon's infection rate by using only the surgeries before the patient we are predicting for. Calculating this for each surgery in your training data may be a little tricky.\n",
    "\n",
    "You also have a train-test contamination problem if you calculate this using all surgeries a surgeon performed, including those from the test-set. The result would be that your model could look very accurate on the test set, even if it wouldn't generalize well to new patients after the model is deployed. This would happen because the surgeon-risk feature accounts for data in the test set. Test sets exist to estimate how the model will do when seeing new data. So this contamination defeats the purpose of the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce1f4f0-5c38-4bd5-b1fe-6c1b263cf646",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1 id='reach-me' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>ðŸ“« | Reach Me</h1>\n",
    "\n",
    "> **Email** - [csfelix08@gmail.com](mailto:csfelix08@gmail.com?)\n",
    "\n",
    "> **Linkedin** - [linkedin.com/in/csfelix/](https://www.linkedin.com/in/csfelix/)\n",
    "\n",
    "> **GitHub:** - [CSFelix](https://github.com/CSFelix)\n",
    "\n",
    "> **Kaggle** - [DSFelix](https://www.kaggle.com/dsfelix)\n",
    "\n",
    "> **Portfolio** - [CSFelix.io](https://csfelix.github.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
